## 集成学习
- 构建多个学习器，然后通过一定策略结合他们来完成学习任务，常常可以获得比单一学习显著优越的学习器，一般分三类：Bagging、Boosting、Stracking，分别是并行，串行，和树型

### Bagging
&emsp;&emsp;各个基算法之间没有依赖，可以并行计算
1. BaggingClassifer/Regressor，从原始数据集抽取数据(有放回)，使用同一模型，训练得到不同的分类器，预测时使用投票最多的分类
2. 随机森林，是对决策树的集成，用随机的方式建立一个决策树的森林，当有一个新的输入样本进入的时候，就让森林中的每一棵树分别进行判断，预测时使用投票结果最多的分类，也是少数服从多数的算法

### Boosting
- 从弱学习器开始加强，通过加权来进行训练
- 一般来说，它的效果会比Bagging好一些，由于新模型是在旧模型的基本上建立的，因此不能使用并行方法训练，并且对于错误样本的关注，也可能造成过拟合

### Stracking
- 聚合多个分类或回归模型(可以分阶段来做)
- Stracking训练一个模型用于组合其他各个模型，具体做法是把数据分成两部分，用其中一部分训练几个基模型A1，A2，A3，用另一部分数据测试这几个基模型，把A1，A2，A3的输出作为输入，训练组合模型B
